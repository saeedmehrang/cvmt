{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d38cc88c-6d0d-4933-a983-d06e55a4ef16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d6393b7-ef7c-4127-934f-68d6111e91d1",
   "metadata": {},
   "source": [
    "# Introduction and Objective\n",
    "## Training with MultiTask Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93501c9d-a008-4b2a-a655-5001517d04a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "647f3e61-f764-4f7e-9c07-1ad7f8fd09db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27ede7ed-71ac-4217-8ef2-d2bd732861a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import (\n",
    "    HDF5MultitaskDataset,\n",
    "    ResizeTransform, \n",
    "    MultitaskCollator,\n",
    "    MultiTaskLandmarkUNet1,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a96a526-d662-447c-8f1b-49ccfee2d17d",
   "metadata": {},
   "source": [
    "# load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e553e5ae-ffb8-47ca-9445-503de8bb4557",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../code_configs/params.yaml\") as f:\n",
    "    params = yaml.safe_load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8dbe68e5-8631-4ace-8c28-b3408f52bd06",
   "metadata": {},
   "source": [
    "# Load metadata table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25606a82-607e-49c6-a213-6ead1166f19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_table = pd.read_hdf(\n",
    "    os.path.join(params['PRIMARY_DATA_DIRECTORY'], params['METADATA_TABLE_NAME']),\n",
    "    key='df',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "578256db-0c4f-49d2-8dd6-5daed2e2a88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_image_filename</th>\n",
       "      <th>harmonized_id</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dev_set</th>\n",
       "      <th>v_annots_present</th>\n",
       "      <th>f_annots_present</th>\n",
       "      <th>edges_present</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.jpg</td>\n",
       "      <td>041281ee7fb89f6835a71c309b3b503e3d5a68fc46a608...</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92.jpg</td>\n",
       "      <td>2cfa37a69916c8a45a51bb8beeb04425e07d2a22f694e0...</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43.jpg</td>\n",
       "      <td>7201dc2be0b97f59a7901004d6496bbe84c440530776db...</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.jpg</td>\n",
       "      <td>2cd4487c03c72d1016ea0a72d1b21eb987878c90ae9eff...</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121.jpg</td>\n",
       "      <td>27624a6eb37bbc8aafabe2075f423d573b189eae6f23fb...</td>\n",
       "      <td>dataset_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>undefined</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  source_image_filename                                      harmonized_id  \\\n",
       "0                45.jpg  041281ee7fb89f6835a71c309b3b503e3d5a68fc46a608...   \n",
       "1                92.jpg  2cfa37a69916c8a45a51bb8beeb04425e07d2a22f694e0...   \n",
       "2                43.jpg  7201dc2be0b97f59a7901004d6496bbe84c440530776db...   \n",
       "3                 7.jpg  2cd4487c03c72d1016ea0a72d1b21eb987878c90ae9eff...   \n",
       "4               121.jpg  27624a6eb37bbc8aafabe2075f423d573b189eae6f23fb...   \n",
       "\n",
       "     dataset dev_set  v_annots_present  f_annots_present  edges_present  \\\n",
       "0  dataset_1     NaN              True             False           True   \n",
       "1  dataset_1     NaN              True             False           True   \n",
       "2  dataset_1     NaN              True             False           True   \n",
       "3  dataset_1     NaN              True             False           True   \n",
       "4  dataset_1     NaN              True             False           True   \n",
       "\n",
       "       split  \n",
       "0  undefined  \n",
       "1  undefined  \n",
       "2  undefined  \n",
       "3  undefined  \n",
       "4  undefined  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_table.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afdc1169-690f-41ea-ab70-dadc7d0f5c3b",
   "metadata": {},
   "source": [
    "# DataLoader for task one: Input Image Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "108c65af-0542-4ed6-b700-287411127cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the task id\n",
    "task_id = 1\n",
    "\n",
    "# create the right list of paths\n",
    "train_file_list = metadata_table.loc[\n",
    "    (metadata_table['split']=='train') , ['harmonized_id']\n",
    "].to_numpy().ravel().tolist()\n",
    "\n",
    "train_file_list = [\n",
    "    os.path.join(params['PRIMARY_DATA_DIRECTORY'], file_path+'.hdf5') for file_path in train_file_list\n",
    "]\n",
    "\n",
    "# instantiate the transforms\n",
    "my_transforms = transforms.Compose([\n",
    "    ResizeTransform(tuple(params['TARGET_IMAGE_SIZE'])),\n",
    "])\n",
    "\n",
    "# instantiate the dataset and dataloader objects\n",
    "train_dataset = HDF5MultitaskDataset(\n",
    "    file_paths=train_file_list,\n",
    "    task_id=task_id,\n",
    "    transforms=my_transforms,\n",
    ")\n",
    "collator_task = MultitaskCollator(\n",
    "    task_id=task_id,\n",
    ")\n",
    "dataloader_one = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=collator_task\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f3ae8b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Sanity check dataset object!\n",
      "dict_keys(['image'])\n",
      "\n",
      "image\n",
      "torch.Size([1, 256, 256])\n",
      "\n",
      "-- Sanity check dataloader object!\n",
      "batch_ndx  0\n",
      "\n",
      "image\n",
      "torch.Size([4, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# sanity check dataset and dataloader\n",
    "\n",
    "# dataset\n",
    "print(\"-- Sanity check dataset object!\")\n",
    "dataset_iter = iter(train_dataset)\n",
    "for batch in dataset_iter:\n",
    "    print(batch.keys())\n",
    "    for k, v in batch.items():\n",
    "        print()\n",
    "        print(k,)\n",
    "        print(v.shape)\n",
    "    break\n",
    "\n",
    "print()\n",
    "\n",
    "# data loader\n",
    "print(\"-- Sanity check dataloader object!\")\n",
    "for batch_ndx, sample in enumerate(dataloader_one):\n",
    "    print(\"batch_ndx \", batch_ndx)\n",
    "    for k, v in sample.items():\n",
    "        print()\n",
    "        print(k,)\n",
    "        print(v.shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "648680a1-aeb7-4aaf-9ffa-8ef68cfc6b42",
   "metadata": {},
   "source": [
    "# DataLoader for task two: Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d9325d7a-c53a-4ea0-b28d-f4ff765a1d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the task id\n",
    "task_id = 2\n",
    "\n",
    "# create the right list of paths\n",
    "train_file_list = metadata_table.loc[\n",
    "    (metadata_table['split']=='train') & (metadata_table['edges_present']==True), ['harmonized_id']\n",
    "].to_numpy().ravel().tolist()\n",
    "\n",
    "train_file_list = [\n",
    "    os.path.join(params['PRIMARY_DATA_DIRECTORY'], file_path+'.hdf5') for file_path in train_file_list\n",
    "]\n",
    "\n",
    "# instantiate the transforms\n",
    "my_transforms = transforms.Compose([\n",
    "    ResizeTransform(tuple(params['TARGET_IMAGE_SIZE'])),\n",
    "])\n",
    "\n",
    "# instantiate the dataset and dataloader objects\n",
    "train_dataset = HDF5MultitaskDataset(\n",
    "    file_paths=train_file_list,\n",
    "    task_id=task_id,\n",
    "    transforms=my_transforms,\n",
    ")\n",
    "collator_task = MultitaskCollator(\n",
    "    task_id=task_id,\n",
    ")\n",
    "dataloader_two = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=collator_task\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e4223f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Sanity check dataset object!\n",
      "dict_keys(['image', 'edges'])\n",
      "\n",
      "image\n",
      "torch.Size([1, 256, 256])\n",
      "\n",
      "edges\n",
      "torch.Size([1, 256, 256])\n",
      "\n",
      "-- Sanity check dataloader object!\n",
      "batch_ndx  0\n",
      "\n",
      "image\n",
      "torch.Size([4, 1, 256, 256])\n",
      "\n",
      "edges\n",
      "torch.Size([4, 1, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# sanity check dataset and dataloader\n",
    "\n",
    "# dataset\n",
    "print(\"-- Sanity check dataset object!\")\n",
    "dataset_iter = iter(train_dataset)\n",
    "for batch in dataset_iter:\n",
    "    print(batch.keys())\n",
    "    for k, v in batch.items():\n",
    "        print()\n",
    "        print(k,)\n",
    "        print(v.shape)\n",
    "    break\n",
    "\n",
    "print()\n",
    "\n",
    "# data loader\n",
    "print(\"-- Sanity check dataloader object!\")\n",
    "for batch_ndx, sample in enumerate(dataloader_two):\n",
    "    print(\"batch_ndx \", batch_ndx)\n",
    "    for k, v in sample.items():\n",
    "        print()\n",
    "        print(k,)\n",
    "        print(v.shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "62929050-b1f4-4fd0-937d-a9ce3bdee51b",
   "metadata": {},
   "source": [
    "# DataLoader for task three: Vertebral Landmark Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "728a4a20-a67a-414c-ba82-ebc9438deff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the task id\n",
    "task_id = 3\n",
    "\n",
    "# create the right list of paths\n",
    "train_file_list = metadata_table.loc[\n",
    "    (metadata_table['split']=='train') & (metadata_table['v_annots_present']==True), ['harmonized_id']\n",
    "].to_numpy().ravel().tolist()\n",
    "\n",
    "train_file_list = [\n",
    "    os.path.join(params['PRIMARY_DATA_DIRECTORY'], file_path+'.hdf5') for file_path in train_file_list\n",
    "]\n",
    "\n",
    "# instantiate the transforms\n",
    "my_transforms = transforms.Compose([\n",
    "    ResizeTransform(tuple(params['TARGET_IMAGE_SIZE'])),\n",
    "])\n",
    "\n",
    "# instantiate the dataset and dataloader objects\n",
    "train_dataset = HDF5MultitaskDataset(\n",
    "    file_paths=train_file_list,\n",
    "    task_id=task_id,\n",
    "    transforms=my_transforms,\n",
    ")\n",
    "collator_task = MultitaskCollator(\n",
    "    task_id=task_id,\n",
    ")\n",
    "dataloader_three = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=collator_task\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a0858658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Sanity check dataset object!\n",
      "dict_keys(['image', 'v_landmarks'])\n",
      "\n",
      "image\n",
      "torch.Size([1, 256, 256])\n",
      "\n",
      "v_landmarks\n",
      "torch.Size([13, 2])\n",
      "\n",
      "-- Sanity check dataloader object!\n",
      "batch_ndx  0\n",
      "\n",
      "image\n",
      "torch.Size([4, 1, 256, 256])\n",
      "\n",
      "v_landmarks\n",
      "torch.Size([4, 13, 2])\n"
     ]
    }
   ],
   "source": [
    "# sanity check dataset and dataloader\n",
    "\n",
    "# dataset\n",
    "print(\"-- Sanity check dataset object!\")\n",
    "dataset_iter = iter(train_dataset)\n",
    "for batch in dataset_iter:\n",
    "    print(batch.keys())\n",
    "    for k, v in batch.items():\n",
    "        print()\n",
    "        print(k,)\n",
    "        print(v.shape)\n",
    "    break\n",
    "\n",
    "print()\n",
    "\n",
    "# data loader\n",
    "print(\"-- Sanity check dataloader object!\")\n",
    "for batch_ndx, sample in enumerate(dataloader_three):\n",
    "    print(\"batch_ndx \", batch_ndx)\n",
    "    for k, v in sample.items():\n",
    "        print()\n",
    "        print(k,)\n",
    "        print(v.shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85c1a823-e32e-47da-b07c-a8e31cd41dc9",
   "metadata": {},
   "source": [
    "# DataLoader for task four: Facial Landmark Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "21627264-7ec1-4978-86cf-e3a7ddb9fec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the task id\n",
    "task_id = 4\n",
    "\n",
    "# create the right list of paths\n",
    "train_file_list = metadata_table.loc[\n",
    "    (metadata_table['split']=='train') & (metadata_table['f_annots_present']==True), ['harmonized_id']\n",
    "].to_numpy().ravel().tolist()\n",
    "\n",
    "train_file_list = [\n",
    "    os.path.join(params['PRIMARY_DATA_DIRECTORY'], file_path+'.hdf5') for file_path in train_file_list\n",
    "]\n",
    "\n",
    "# instantiate the transforms\n",
    "my_transforms = transforms.Compose([\n",
    "    ResizeTransform(tuple(params['TARGET_IMAGE_SIZE'])),\n",
    "])\n",
    "\n",
    "# instantiate the dataset and dataloader objects\n",
    "train_dataset = HDF5MultitaskDataset(\n",
    "    file_paths=train_file_list,\n",
    "    task_id=task_id,\n",
    "    transforms=my_transforms,\n",
    ")\n",
    "collator_task = MultitaskCollator(\n",
    "    task_id=task_id,\n",
    ")\n",
    "dataloader_four = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=collator_task\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "22aba645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Sanity check dataset object!\n",
      "dict_keys(['image', 'f_landmarks'])\n",
      "\n",
      "image\n",
      "torch.Size([1, 256, 256])\n",
      "\n",
      "f_landmarks\n",
      "torch.Size([19, 2])\n",
      "\n",
      "-- Sanity check dataloader object!\n",
      "batch_ndx  0\n",
      "\n",
      "image\n",
      "torch.Size([4, 1, 256, 256])\n",
      "\n",
      "f_landmarks\n",
      "torch.Size([4, 19, 2])\n"
     ]
    }
   ],
   "source": [
    "# sanity check dataset and dataloader\n",
    "\n",
    "# dataset\n",
    "print(\"-- Sanity check dataset object!\")\n",
    "dataset_iter = iter(train_dataset)\n",
    "for batch in dataset_iter:\n",
    "    print(batch.keys())\n",
    "    for k, v in batch.items():\n",
    "        print()\n",
    "        print(k,)\n",
    "        print(v.shape)\n",
    "    break\n",
    "\n",
    "print()\n",
    "\n",
    "# data loader\n",
    "print(\"-- Sanity check dataloader object!\")\n",
    "for batch_ndx, sample in enumerate(dataloader_four):\n",
    "    print(\"batch_ndx \", batch_ndx)\n",
    "    for k, v in sample.items():\n",
    "        print()\n",
    "        print(k,)\n",
    "        print(v.shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5052f338-0077-45a7-8ace-c6302a18b48f",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21f14e73-1816-4ee4-8a56-81fab146179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiTaskLandmarkUNet1(\n",
    "    in_channels=3,\n",
    "    out_channels1=1,\n",
    "    out_channels2=1,\n",
    "    out_channels3=13,\n",
    "    out_channels4=19,\n",
    "    enc_chan_multiplier=1,\n",
    "    dec_chan_multiplier=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "805bb3d8-8c07-4d6f-97f0-b484508b28d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters:  407442\n"
     ]
    }
   ],
   "source": [
    "# count the number of trainable parameters\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Total number of trainable parameters: \", num_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
