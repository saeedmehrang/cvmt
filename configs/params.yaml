RAW_DATA_DIRECTORY: "data/raw"
INTERMEDIATE_DATA_DIRECTORY: "data/intermediate"
PRIMARY_DATA_DIRECTORY: "data/primary"
ARTIFACTS_DATA_DIRECTORY: "artifacts"
ARTIFACTS_GRAPHS_DIR_NAME: "sample_graphs"

# intermediate stage data config
INTERM:
  UNWANTED_JSON_FIELDS: ['imageData', 'imagePath']
  N_PROCESSES: 16

  DATASET_1:
    DIR_NAME: "dataset_1-20231101T081418Z-001"
    IMG_DIR_NAME: ["image"]
    V_LANDMARKS_DIR_NAME: ["label"]
    F_LANDMARKS_DIR_NAME: null

  DATASET_2:
    DIR_NAME: "dataset_2-20230919T192724Z-001"
    IMG_DIR_NAME: ["image"]
    V_LANDMARKS_DIR_NAME: ["label"]
    F_LANDMARKS_DIR_NAME: null

  DATASET_3:
    DIR_NAME: "dataset_3-20230919T192724Z-001"
    IMG_DIR_NAME: ["training/image", "test1/image", "test2/image"]
    V_LANDMARKS_DIR_NAME: ["training/label", "test1/label", "test2/label"] 
    F_LANDMARKS_DIR_NAME: "AnnotationsByMD/400_senior"

  DATASET_4:
    DIR_NAME: "dataset_4-20230919T192724Z-001"
    IMG_DIR_NAME: ["image"]
    V_LANDMARKS_DIR_NAME: ["label"]
    F_LANDMARKS_DIR_NAME: null
    AGE_DATA_TABLE_NAME: "dataset_4_age.csv"

# primary stage data config
PRIMARY:
  DATASET_1:
    EDGE_DETECT_SIGMA: 3
  DATASET_2:
    EDGE_DETECT_SIGMA: 3
  DATASET_3:
    EDGE_DETECT_SIGMA: 3
  DATASET_4:
    EDGE_DETECT_SIGMA: 3

# training: primary stage data config
TRAIN:
  METADATA_TABLE_NAME: 'metadata.hdf5'
  DATASETS_TO_INCLUDE: ['dataset_1', 'dataset_2', 'dataset_3', 'dataset_4']
  CHECKPOINT_PATH: null # An string for tha path to a model checkpoint to be used as a 
  # pretrained model or continuing the training.
  V_LANDMARK_TASK:
    TASK_ID: 3
    BATCH_SIZE: 16
    SHUFFLE: False
  EDGE_DETECT_TASK:
    TASK_ID: 2
    BATCH_SIZE: 16
    SHUFFLE: False
  SAMPLER_N_SAMPLES: 1024 # null or int
  MAX_EPOCHS: 400
  N_WORKERS_DATA_LOADER: 10
  LOSS_NAME: focal_loss # options are L1, mse, focal_loss, cross_entropy
  OPTIMIZER:
    optimizer_name: adam # choises are Adam, SGD, ASGD
    ## the parameters below will be directly passed to the scheduler you named above!
    # nesterov: False
    # momentum: 0.9
    lr: 0.0001
  SCHEDULER:
    scheduler_name: null # null for no scheduler, options are cawslr for CosineAnnealingWarmRestarts, calr, stlr for StepLR
    ## the parameters below will be directly passed to the scheduler you named above!
    # T_0: 10
    # T_mult: 2
  DEVICES: 1 # m for m GPUs, or 1 for CPU
  ACCELERATOR: gpu
  TRANSFORMS: # uncomment the trasnforms that you desire. You can also shuffle their order!
    TRAIN:
      CUSTOMRESIZE:
        size: [256, 256] # H, W - change this when enough RAM is available
      COORD2HEATMAP:
        gauss_std: 1.0
      CUSTOMTOTENSOR:
        {} # put empty curly braces (dict) if there is no parameter
      SCALE01:
        {}
      RANDOMROTATION: 
        degrees: [5, 10] # The min and max number of degrees to rotate in between
        p: 0.5 # p means probability here and in the rest of transforms
      # RANDOMFLIP: 
      #   p: 0.5
      GAUSSIANBLUR: 
        kernel_size: 3
        sigma: 0.2
        p: 0.1
      RIGHTRESIZECROP: 
        width_scale_low: 0.6
        width_scale_high: 1.0
        p: 0.5
      RANDOMBRIGHTNESS: 
        low: 0.8
        high: 1.5
        p: 0.2
    VAL:
      CUSTOMRESIZE:
        size: [256, 256] # H, W - change this when enough RAM is available
      COORD2HEATMAP:
        gauss_std: 1.0
      CUSTOMTOTENSOR:
        {} # put empty curly braces (dict) if there is no parameter
      SCALE01:
        {}

MODEL:
  DEVICE: "cuda"
  PARAMS:
    model_name: custom_unet # available names are unet_cl2023, unet_cl2023_pretrained, custom_unet
    ## the parameters below will be directly passed to the model you named above!
    backbone_encoder: "timm-efficientnet-b2"  # one of https://github.com/qubvel/segmentation_models.pytorch#encoders
    backbone_weights: "noisy-student"
    freeze_backbone: False
    enc_chan_multiplier: 1
    dec_chan_multiplier: 1
    enc_out_chans: [4, 8, 16, 32, 64]
    dec_out_chans: [128, 128, 64, 64, 32]
    enc_chan_multiplier: 1
    dec_chan_multiplier: 1
    in_channels: 1
    out_channels1: 1
    out_channels2: 1
    out_channels3: 13
    out_channels4: 19

WANDB:
  INIT:
    project: "cephal-landmark-detection"
    notes: "Setting optimizer to Adam, and no learning rate scheduler! bug in mre metric fixed!"
    tags: ["timm-efficientnet-b2", "Adam", "W/rotation-aug"]
    id: urt7dgbp # set to null if you do not want to resume a previous run
    resume: must # set to null when no id is given
  CHECKPOINTING:
    dir: "artifacts/artifacts"

VERIFY:
  WANDB_CHECKPOINT_REFERENCE_NAME: sm-data-science/cephal-landmark-detection/model-urt7dgbp:v47 # copy from wandb artifacts webpage
  N_IMGAES_TO_PLOT: 6 # insert an even number

TEST:
  CHECKPOINT_PATH: artifacts/model-urt7dgbp:v47/model.ckpt # An string for tha path to a model checkpoint to be loaded
  LOSS_NAME: focal_loss # options are L1, mse, focal_loss, cross_entropy
  DEVICES: 1 # m for m GPUs, or 1 for CPU
  ACCELERATOR: gpu
  SAMPLER_N_SAMPLES: null # null or int
  V_LANDMARK_TASK:
    TASK_ID: 3
    BATCH_SIZE: 1
    SHUFFLE: False
  TRANSFORMS:
    TEST:
      CUSTOMRESIZE:
        size: [256, 256] # H, W - change this when enough RAM is available
      COORD2HEATMAP:
        gauss_std: 1.0
      CUSTOMTOTENSOR:
        {} # put empty curly braces (dict) if there is no parameter
      SCALE01:
        {}

INFERENCE:
  TRANSFORMS:
    RESIZE:
      size: [256, 256] # H, W - change this when enough RAM is available
    GRAYSCALE:
      num_output_channels: 1
    TOTENSOR:
      {}
  MCNAMARA:
    ARGS:
      concavity_thresh: 1.0 # 1.0 millimiter
      ant_pos_thresh: 0.95 # anterior/posterior length ratio
      sup_inf_thresh: 0.95 # superior/inferior length ratio
      rect_thresh_min: 0.95 # horizontal to vertical ratio min
      rect_thresh_max: 1.05 # horizontal to vertical ratio max
