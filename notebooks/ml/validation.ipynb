{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf6cbde-3843-45bf-a26e-0b24d6085f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a74ecde-1633-4273-8b66-2f79ea378ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import wandb\n",
    "from easydict import EasyDict\n",
    "from cvmt.ml.trainer import create_dataloader, SingletaskTraining, mean_radial_error, max_indices_4d_tensor\n",
    "from cvmt.utils import (load_yaml_params, nested_dict_to_easydict)\n",
    "\n",
    "from cvmt.ml.models import load_model\n",
    "\n",
    "import torch\n",
    "from typing import *\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440bc898-fe8d-44bf-b375-9e6162f76c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8a267c-6cc3-4f68-a3e2-dfe4af7cb091",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source configs/.env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1be818-80fb-48fa-ae21-045dd926e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PARAMS_PATH = \"configs/params.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8c54bf-2b30-4b63-85a9-452d8c0999cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "params: EasyDict = nested_dict_to_easydict(\n",
    "    load_yaml_params(CONFIG_PARAMS_PATH)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ed631-9569-4dc6-b72f-77ed3e86ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if params.VERIFY.CHECKPOINT_PATH:\n",
    "    # create the checkpoint path\n",
    "    checkpoint_path = params.VERIFY.CHECKPOINT_PATH\n",
    "elif params.TEST.WANDB_CHECKPOINT_REFERENCE_NAME:\n",
    "    try:\n",
    "        # setup wandb\n",
    "        user = \"sm-data-science\"\n",
    "        project = params.WANDB.INIT.project\n",
    "\n",
    "        # load the best model\n",
    "        api = wandb.Api()\n",
    "\n",
    "        # create the checkpoint path\n",
    "        checkpoint_reference = params.VERIFY.WANDB_CHECKPOINT_REFERENCE_NAME\n",
    "        artifact = api.artifact(checkpoint_reference)\n",
    "        artifact_dir = artifact.download()\n",
    "        checkpoint_path = artifact_dir+\"/model.ckpt\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"You have to define either `TEST.CHECKPOINT_PATH` or \"\n",
    "        \"`TEST.WANDB_CHECKPOINT_REFERENCE_NAME` in the config/params.yaml\"\n",
    ")\n",
    "\n",
    "print(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcb8894-be4d-45d3-b8ff-ffcb3f8c393c",
   "metadata": {},
   "source": [
    "## Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2be4d9-fe34-45fc-aee6-99cb139be7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pretrain = True\n",
    "\n",
    "task_config = params.TRAIN.V_LANDMARK_TASK\n",
    "task_id = task_config.TASK_ID\n",
    "batch_size = task_config.BATCH_SIZE\n",
    "\n",
    "loss_name = params.TRAIN.LOSS_NAME\n",
    "optim_params = params.TRAIN.OPTIMIZER\n",
    "model_params = params.MODEL.PARAMS\n",
    "\n",
    "n_images_to_plot = params.VERIFY.N_IMGAES_TO_PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f64ae-edd3-45c9-83d9-08fbd5016f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val dataloader\n",
    "train_dataloader = create_dataloader(\n",
    "    task_id=task_id,\n",
    "    batch_size=1,\n",
    "    split='train',\n",
    "    shuffle=False,\n",
    "    params=params,\n",
    "    sampler_n_samples=None,\n",
    ")\n",
    "# val dataloader\n",
    "val_dataloader = create_dataloader(\n",
    "    task_id=task_id,\n",
    "    batch_size=1,\n",
    "    split='val',\n",
    "    shuffle=False,\n",
    "    params=params,\n",
    "    sampler_n_samples=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835de696-5d97-4da0-8860-874cc4ea0c7b",
   "metadata": {},
   "source": [
    "## Load the model\n",
    "### use a pytorch lighning module for model class mother"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e831b0a2-6de1-49ab-9cf8-7c5cc11c6c81",
   "metadata": {},
   "source": [
    "See the issue below for why a pytorch lightning model cannot be loaded from checkpoint with hparams saved\n",
    "and how to use pytorch lighning module to enable using a model that is defined outside a pl module.\n",
    "\n",
    "https://github.com/Lightning-AI/lightning/issues/3629#issue-707536217"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b7456d-c815-475f-9708-b8740779ebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(**model_params)\n",
    "\n",
    "pl_module = SingletaskTraining(\n",
    "    model=model,\n",
    "    task_id=task_id,\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    loss_name=loss_name,\n",
    ")\n",
    "\n",
    "if use_pretrain:\n",
    "    model = pl_module.load_from_checkpoint(checkpoint_path,).model\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "# model.double()\n",
    "\n",
    "val_radial_errors = []\n",
    "\n",
    "counter_perf = 1\n",
    "counter_med = 1\n",
    "counter_bad = 1\n",
    "\n",
    "perf_samples = []\n",
    "med_samples = []\n",
    "bad_samples = []\n",
    "\n",
    "for i, batch in enumerate(val_dataloader):\n",
    "    images, targets = batch['image'], batch['v_landmarks']\n",
    "    images = images.to(device)\n",
    "    targets = targets.to(device)\n",
    "    # Pass images through the model\n",
    "    with torch.no_grad():\n",
    "        predictions = model(images, task_id=task_id)\n",
    "        \n",
    "    mre = mean_radial_error(preds=predictions, targets=targets)\n",
    "    mre = mre.item()\n",
    "    val_radial_errors.append(mre)\n",
    "    \n",
    "    preds_coords = max_indices_4d_tensor(predictions)\n",
    "    preds_coords = preds_coords.cpu().numpy()\n",
    "    preds_coords = np.squeeze(preds_coords)\n",
    "    \n",
    "    targs_coords = max_indices_4d_tensor(targets)\n",
    "    targs_coords = targs_coords.cpu().numpy()\n",
    "    targs_coords = np.squeeze(targs_coords)\n",
    "    \n",
    "    landmarks_coords = {'preds': preds_coords, 'targets': targs_coords}\n",
    "    image = images[0].cpu().numpy()\n",
    "    \n",
    "    if mre >= 9.6 and counter_bad <= n_images_to_plot:\n",
    "        # store the sample\n",
    "        print(f\"bad - counter: {counter_bad} , mre: {mre}\")\n",
    "        bad_samples.append([image, landmarks_coords, mre,])\n",
    "        counter_bad += 1\n",
    "\n",
    "    if mre <= 9.6 and mre >= 1.22 and counter_med <= n_images_to_plot:\n",
    "        # store the sample\n",
    "        print(f\"med - counter: {counter_med} , mre: {mre}\")\n",
    "        med_samples.append([image, landmarks_coords, mre,])\n",
    "        counter_med += 1\n",
    "\n",
    "    if mre < 1.22 and counter_perf <=n_images_to_plot:\n",
    "        # store the sample\n",
    "        print(f\"perf - counter: {counter_perf} , mre: {mre}\")\n",
    "        perf_samples.append([image, landmarks_coords, mre,])\n",
    "        counter_perf += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557e052d-f88f-41c2-a243-859d2befe696",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(val_radial_errors), np.percentile(val_radial_errors, 25), np.percentile(val_radial_errors, 75), np.mean(val_radial_errors), np.std(val_radial_errors), "
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab375479-db28-4674-bed0-e3525c05dd35",
   "metadata": {},
   "source": [
    "train_radial_errors = []\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    images, labels = batch['image'], batch['v_landmarks']\n",
    "    images = images.to(device)\n",
    "    # Pass images through the model\n",
    "    with torch.no_grad():\n",
    "        predictions = model(images, task_id=task_id)\n",
    "        \n",
    "    train_radial_errors.append(mean_radial_error(preds=predictions, targets=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bd5550-0898-4825-9537-168673aee6c7",
   "metadata": {},
   "source": [
    "## Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a92f18-708c-4bef-a8d3-198c8f02b13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_and_landmark_coords(items: List[Any], category: str='all'):\n",
    "    \n",
    "    # if user desires a specific category\n",
    "    if category == 'all':\n",
    "        categories = ['preds', 'targets']\n",
    "    else:\n",
    "        categories = [category]\n",
    "\n",
    "    # Calculate the number of rows for subplots\n",
    "    if len(items)> 1:\n",
    "        rows = len(items) // 2\n",
    "        fig, axs = plt.subplots(rows, 2, figsize=(16, 8*rows))\n",
    "        axs = axs.flatten()\n",
    "    else:\n",
    "        fig, axs = plt.subplots(1, 1, figsize=(16,16))\n",
    "        axs = [axs]\n",
    "\n",
    "    for ax, item in zip(axs, items):\n",
    "        image, landmarks, mre = item\n",
    "        image = image.squeeze()\n",
    "        target_landmarks = landmarks['targets']\n",
    "        pred_landmarks = landmarks['preds']\n",
    "        ax.imshow(image, cmap='gray',)\n",
    "        if 'targets' in categories:\n",
    "            for landmark in target_landmarks:\n",
    "                # Assuming each landmark is a tuple of (x, y) coordinates\n",
    "                ax.add_patch(patches.Circle((landmark[1], landmark[0]), radius=1, color='yellow'))\n",
    "        if 'preds' in categories:\n",
    "            for landmark in pred_landmarks:\n",
    "                # Assuming each landmark is a tuple of (x, y) coordinates\n",
    "                ax.add_patch(patches.Circle((landmark[1], landmark[0]), radius=1, color='cyan'))\n",
    "        ax.set_title(f'MRE={mre}')  # Set your title here\n",
    "\n",
    "    # Create a legend\n",
    "    legend_elements = [Line2D([0], [0], marker='o', color='w', label='Target Landmarks',\n",
    "                              markerfacecolor='yellow', markersize=10),\n",
    "                       Line2D([0], [0], marker='o', color='w', label='Predicted Landmarks',\n",
    "                              markerfacecolor='cyan', markersize=10)]\n",
    "    \n",
    "    # Place the legend on the axes\n",
    "    for ax in axs:\n",
    "        ax.legend(handles=legend_elements, loc='lower right')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbc2105-7120-4e30-9b44-f074b545d390",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_and_landmark_coords(perf_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6307773-35a2-4438-bcbd-518ce902b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_and_landmark_coords(med_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133c0789-c3ab-4bcb-a966-7dac879ca6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_and_landmark_coords(bad_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f201db0f-ed9d-406f-a4a5-9cdfd9c09798",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
