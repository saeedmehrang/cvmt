{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d452a37b-6cee-4fad-a297-890db5dba0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "507ccfc0-7847-4b53-a9f4-150046c6ef61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samehr/miniconda3/envs/cephal/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/samehr/miniconda3/envs/cephal/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.25.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from cvmt.utils import (load_yaml_params, nested_dict_to_easydict)\n",
    "from cvmt.utils import (\n",
    "    img_coord_2_cartesian_coord,\n",
    "    translate_landmarks,\n",
    "    rotate_landmarks,\n",
    "    plot_landmarks,\n",
    "    normalize_coords,\n",
    "    plot_image_and_vertebral_landmarks,\n",
    ")\n",
    "\n",
    "from cvmt.ml.utils import download_wandb_model_checkpoint\n",
    "from cvmt.ml.trainer import create_dataloader, max_indices_4d_tensor\n",
    "from cvmt.inference.inference import load_pretrained_model_eval_mode\n",
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b099be-1708-4a5f-bf49-25869e7af144",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54f3f77f-ec0a-4c35-b9ed-bad99f7bc380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cartesian_to_polar(coords):\n",
    "    \"\"\"Transform cartesian coordiantes to polar coordinates.\"\"\"\n",
    "    r = np.sqrt(coords[..., 0]**2 + coords[..., 1]**2)\n",
    "    theta = np.arctan2(coords[..., 1], coords[..., 0])\n",
    "    return np.stack((r, theta), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b304bc59-1fbc-4613-b98a-5a71462bf2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_vertebral_landmarks(\n",
    "    landmarks: np.ndarray,\n",
    "    swap_x_y: bool = False,\n",
    "    plot: bool = False,\n",
    "    retrieve_orig_position: bool = False,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Rotate, translate, and normalize the vertebral landmarks. The\n",
    "    normalization is done with respect to the distance between the 2\n",
    "    points at the left and right of the base of each shape.\n",
    "    \"\"\"\n",
    "    c2, c3, c4 = landmarks[0:3].copy(), landmarks[3:8].copy(), landmarks[8:].copy()\n",
    "    c2_cart = img_coord_2_cartesian_coord(c2, swap_x_y) \n",
    "    c2_ref_index_tr = 0\n",
    "    c2_trns = translate_landmarks(c2_cart, ref_index=c2_ref_index_tr)\n",
    "    c2_ref_index_rot = 2\n",
    "    c2_trns_rot = rotate_landmarks(c2_trns, ref_index=c2_ref_index_rot)\n",
    "    c2_trns_rot_nr = 2\n",
    "    c2_trns_rot_n = normalize_coords(\n",
    "        landmarks=c2_trns_rot,\n",
    "        ref_index=c2_trns_rot_nr,\n",
    "        height_wise=False,\n",
    "    )\n",
    "    if plot:\n",
    "        plot_landmarks(c2_trns_rot_n)\n",
    "    c3_cart = img_coord_2_cartesian_coord(c3, swap_x_y)\n",
    "    c3_ref_index_tr = 1\n",
    "    c3_trns = translate_landmarks(c3_cart, ref_index=c3_ref_index_tr)\n",
    "    c3_ref_index_rot = 3\n",
    "    c3_trns_rot = rotate_landmarks(c3_trns, ref_index=c3_ref_index_rot)\n",
    "    c3_ref_index_nr = 3\n",
    "    c3_trns_rot_n = normalize_coords(\n",
    "        landmarks=c3_trns_rot,\n",
    "        ref_index=c3_ref_index_nr,\n",
    "        height_wise=False,\n",
    "    )\n",
    "    if plot:\n",
    "        plot_landmarks(c3_trns_rot_n)\n",
    "    c4_cart = img_coord_2_cartesian_coord(c4, swap_x_y)\n",
    "    c4_ref_index_tr = 1\n",
    "    c4_trns = translate_landmarks(c4_cart, ref_index=c4_ref_index_tr)\n",
    "    c4_ref_index_rot = 3\n",
    "    c4_trns_rot = rotate_landmarks(c4_trns, ref_index=c4_ref_index_rot)\n",
    "    c4_ref_index_nr = 3\n",
    "    c4_trns_rot_n = normalize_coords(\n",
    "        landmarks=c4_trns_rot,\n",
    "        ref_index=c4_ref_index_nr,\n",
    "        height_wise=False,\n",
    "    )\n",
    "    if plot:\n",
    "        plot_landmarks(c4_trns_rot_n)\n",
    "    # retrieve the original distance of the vertebrae\n",
    "    if retrieve_orig_position:\n",
    "        c24_cart_dist = np.abs(c2_cart[c2_ref_index] - c4_cart[c4_ref_index])/c4_trns_rot[c4_ref_index_nr]\n",
    "        c34_cart_dist = np.abs(c3_cart[c3_ref_index] - c4_cart[c4_ref_index])/c4_trns_rot[c4_ref_index_nr]\n",
    "        c2_trns_rot_n += c24_cart_dist\n",
    "        c3_trns_rot_n += c34_cart_dist\n",
    "    normalized_landmarks = np.vstack((c2_trns_rot_n, c3_trns_rot_n, c4_trns_rot_n))\n",
    "    return normalized_landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ed58d5-4b38-4cf0-8a29-3b1ac8a97fe6",
   "metadata": {},
   "source": [
    "# Stage Clustering\n",
    "\n",
    "In this notebook, we see how we can utilize the nominal patterns of the different stages that were\n",
    "reported by McNamara and Franchi into a clustering tasks. The nominal patterns serve as the\n",
    "characteristics of the cluster centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b3cb6c9-dafc-4b35-9bec-c34bb7c104d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../\")\n",
    "!source configs/.env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9682d4a9-8f88-4900-af6d-0db7679fc948",
   "metadata": {},
   "source": [
    "## Load parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89f820bc-3ef9-44b3-a033-4c8736b41a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PARAMS_PATH = \"configs/params.yaml\"\n",
    "\n",
    "params = nested_dict_to_easydict(\n",
    "    load_yaml_params(CONFIG_PARAMS_PATH)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6759bcf6-4ebd-43a3-bcd4-2f15737315ca",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "551f6746-1ab5-4086-9b01-2ddc4cba99b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact model-urt7dgbp:v47, 100.36MB. 1 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "Done. 0:0:0.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./artifacts/model-urt7dgbp:v47/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path, model_id = download_wandb_model_checkpoint(\n",
    "    wandb_checkpoint_uri= params.VERIFY.WANDB_CHECKPOINT_REFERENCE_NAME\n",
    ")\n",
    "print(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b03bb215-7f0d-459c-bc15-5fc571565e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pretrain = True\n",
    "\n",
    "task_config = params.TRAIN.V_LANDMARK_TASK\n",
    "task_id = task_config.TASK_ID\n",
    "\n",
    "loss_name = params.TRAIN.LOSS_NAME\n",
    "model_params = params.MODEL.PARAMS\n",
    "transforms_params = params.INFERENCE.TRANSFORMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9c912fb-86d4-43f8-b4b3-0de382ada563",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samehr/miniconda3/envs/cephal/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:197: UserWarning: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "model, device = load_pretrained_model_eval_mode(\n",
    "    model_params=model_params,\n",
    "    use_pretrain=use_pretrain,\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    task_id=task_id,\n",
    "    loss_name=loss_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b596520e-96fa-421e-a014-92ccca7d0362",
   "metadata": {},
   "source": [
    "## Load and process cluster centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf31d3b8-5808-4228-85b0-10d9b4548ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers = []\n",
    "for i in range(1,7):\n",
    "    cs_df = pd.read_csv(\n",
    "        os.path.join(\n",
    "            params.INTERMEDIATE_DATA_DIRECTORY, \"stages_nominal_patterns\", f\"cs{i}.csv\"\n",
    "        ),\n",
    "        header=None,\n",
    "        names=['index', 'x', 'y']\n",
    "    )\n",
    "    cs = cs_df.iloc[:, 1:].to_numpy()\n",
    "    normalized_landmarks = post_process_vertebral_landmarks(\n",
    "        landmarks=cs, swap_x_y=False, plot=False,\n",
    "    )\n",
    "    cluster_centers.append(normalized_landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03fcf1f-87d4-4a9d-8516-97b9e255ba50",
   "metadata": {},
   "source": [
    "## Load training and validation set data, predict, and process the landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3c1c50d-bd78-4bd3-a735-e04cd579c035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataloader\n",
    "train_dataloader = create_dataloader(\n",
    "    task_id=task_id,\n",
    "    batch_size=1,\n",
    "    split='train',\n",
    "    shuffle=False,\n",
    "    params=params,\n",
    "    sampler_n_samples=None,\n",
    ")\n",
    "# val dataloader\n",
    "val_dataloader = create_dataloader(\n",
    "    task_id=task_id,\n",
    "    batch_size=1,\n",
    "    split='val',\n",
    "    shuffle=False,\n",
    "    params=params,\n",
    "    sampler_n_samples=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bf15284-5969-4848-ab6e-e67c92c377ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = []\n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    images, targets = batch['image'], batch['v_landmarks']\n",
    "    images = images.to(device)\n",
    "    targets = targets.to(device)\n",
    "    # Pass images through the model\n",
    "    with torch.no_grad():\n",
    "        lmks = model(images, task_id=task_id)\n",
    "    # turn heatmaps to coordinates\n",
    "    lmks = max_indices_4d_tensor(lmks)\n",
    "    lmks = lmks.squeeze()\n",
    "    lmks = lmks.cpu().numpy()\n",
    "    # process coordinates\n",
    "    normalized_landmarks = post_process_vertebral_landmarks(\n",
    "        landmarks=lmks, swap_x_y=True, plot=False,)\n",
    "    train_set.append(normalized_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a46bc95d-b19d-41e0-8c7f-0e16be3a0ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = []\n",
    "for i, batch in enumerate(val_dataloader):\n",
    "    images, targets = batch['image'], batch['v_landmarks']\n",
    "    images = images.to(device)\n",
    "    targets = targets.to(device)\n",
    "    # Pass images through the model\n",
    "    with torch.no_grad():\n",
    "        lmks = model(images, task_id=task_id)\n",
    "    # turn heatmaps to coordinates\n",
    "    lmks = max_indices_4d_tensor(lmks)\n",
    "    lmks = lmks.squeeze()\n",
    "    lmks = lmks.cpu().numpy()\n",
    "    # process coordinates\n",
    "    normalized_landmarks = post_process_vertebral_landmarks(\n",
    "        landmarks=lmks, swap_x_y=True, plot=False,)\n",
    "    val_set.append(normalized_landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112b9d20-3527-4b65-83ee-6cfcd518818c",
   "metadata": {},
   "source": [
    "## flatten original coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37d371fb-261e-42b6-a6fc-61b4549c2b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.array(train_set)\n",
    "val_set = np.array(val_set)\n",
    "cluster_centers = np.array(cluster_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7cd3126-33fd-4262-a525-1bb84371b4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_fl = train_set.reshape(train_set.shape[0], -1)\n",
    "val_set_fl = val_set.reshape(val_set.shape[0], -1)\n",
    "cluster_centers_fl = cluster_centers.reshape(cluster_centers.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7339a46e-7b0b-401b-99e7-74c46c4cd89a",
   "metadata": {},
   "source": [
    "# Polar coordinates"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6c8c190d-b7be-4fe9-8815-b0e8c71b7097",
   "metadata": {},
   "source": [
    "train_set_polar = train_set_polar.reshape(train_set_polar.shape[0], -1)\n",
    "val_set_polar = val_set_polar.reshape(val_set_polar.shape[0], -1)\n",
    "cluster_centers_polar = cluster_centers_polar.reshape(cluster_centers_polar.shape[0], -1)\n",
    "\n",
    "fig, axs = plt.subplots(2,1, figsize=(5,5))\n",
    "for i, c in enumerate(cluster_centers_polar):\n",
    "    axs[0].plot(c[:,0], label=f\"cs{i}\")\n",
    "    axs[1].plot(c[:,1], label=f\"cs{i}\")\n",
    "axs[0].set_title('r')\n",
    "axs[1].set_title('theta')\n",
    "plt.tight_layout()\n",
    "plt.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05454475-f0c4-48aa-aca1-55578922fb42",
   "metadata": {},
   "source": [
    "# Fit to PCA"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d55e0fb-c219-48fc-90f7-4c62583614fd",
   "metadata": {},
   "source": [
    "pca = PCA(n_components=3)  # you can change the number of components\n",
    "\n",
    "# Fit and transform the data\n",
    "clusters_pca = pca.fit_transform(cluster_centers_fl)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "168a44fe-d4f7-4b72-bd65-d4873bb24c19",
   "metadata": {},
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "for i, c_pca in enumerate(clusters_pca):\n",
    "    ax.scatter(c_pca[0] , c_pca[1], c_pca[2], label=str(i))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "86d2a3dc-af26-4c20-b699-74248ef92a7b",
   "metadata": {},
   "source": [
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "55c56aad-adc7-4a21-aff5-a7cceceda8e9",
   "metadata": {},
   "source": [
    "val_set_pca = pca.transform(val_set_fl)\n",
    "train_set_pca = pca.transform(train_set_fl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef26b99-ec12-4c56-80af-1404ea227e38",
   "metadata": {},
   "source": [
    "# Fit PCA coordinates to the KMeans"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10a9c882-9e15-40a6-960e-02538e9d955e",
   "metadata": {},
   "source": [
    "# Define initial cluster centers\n",
    "init_centers = np.array(clusters_pca)\n",
    "\n",
    "# Create KMeans object with initial centers\n",
    "kmeans = KMeans(n_clusters=6, init=init_centers, n_init=1)\n",
    "\n",
    "# Fit the model to your data\n",
    "kmeans.fit(train_set_pca)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cdc3e498-3613-4849-a468-8dfa59131e73",
   "metadata": {},
   "source": [
    "train_set_clusters = kmeans.predict(train_set_pca)\n",
    "np.unique(train_set_clusters, return_counts=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7094e5d2-e464-4041-9e33-5d31304fa863",
   "metadata": {},
   "source": [
    "val_set_clusters = kmeans.predict(val_set_pca)\n",
    "np.unique(val_set_clusters, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164abb84-62ac-47f3-b0c6-7804a59ac72a",
   "metadata": {},
   "source": [
    "# Fit raw flattened coordinates to the KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ad9147e-d448-4938-b83f-e4e4587db4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(init=array([[ 0.  ,  0.  ,  0.5 ,  0.01,  1.  ,  0.  , -0.05,  0.77,  0.  ,\n",
       "         0.  ,  0.51, -0.01,  1.  ,  0.  ,  0.96,  0.33, -0.05,  0.77,\n",
       "         0.  ,  0.  ,  0.52, -0.01,  1.  ,  0.  ,  0.98,  0.33],\n",
       "       [ 0.  ,  0.  ,  0.41,  0.17,  1.  ,  0.  , -0.03,  0.77,  0.  ,\n",
       "         0.  ,  0.48, -0.01,  1.  ,  0.  ,  0.96,  0.33, -0.06,  0.78,\n",
       "         0.  ,  0.  ,  0.5 ,  0.01,  1.  , -0.  ,  0.96,  0.32],\n",
       "       [ 0.  ,  0.  ,  0.45,  0.19,  1.  ,  0.  , -0.06,  0.78,  0.  ,\n",
       "         0.  ,  0.5 ,  0.08,  1.  , -0.  ,  0.9 ,  0.55, -0.06,  0.78,\n",
       "         0.  ,  0.  ,  0.52, -0.02,  1.  , -0.  ,  0.97,  0.33],\n",
       "       [ 0.  ,  0.  ,  0.47,  0.17,  1.  ,  0.  , -0.01,  0.81,  0.  ,\n",
       "         0.  ,  0.5 ,  0.16,  1.  , -0.  ,  1.02,  0.71, -0.03,  0.77,\n",
       "         0.  ,  0.  ,  0.48,  0.14,  1.  ,  0.  ,  1.  ,  0.7 ],\n",
       "       [ 0.  ,  0.  ,  0.46,  0.2 ,  1.  , -0.  , -0.02,  1.03,  0.  ,\n",
       "         0.  ,  0.49,  0.18,  1.  ,  0.  ,  0.98,  0.97,  0.  ,  1.02,\n",
       "         0.  ,  0.  ,  0.48,  0.17,  1.  ,  0.  ,  0.98,  0.95],\n",
       "       [ 0.  ,  0.  ,  0.48,  0.18,  1.  ,  0.  , -0.01,  1.14,  0.  ,\n",
       "         0.  ,  0.49,  0.2 ,  1.  ,  0.  ,  0.97,  1.09, -0.02,  1.14,\n",
       "         0.  ,  0.  ,  0.49,  0.18,  1.  ,  0.  ,  0.95,  1.11]]),\n",
       "       n_clusters=6, n_init=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define initial cluster centers\n",
    "init_centers = np.array(cluster_centers_fl)\n",
    "\n",
    "# Create KMeans object with initial centers\n",
    "kmeans = KMeans(n_clusters=6, init=init_centers, n_init=1)\n",
    "\n",
    "# Fit the model to your data\n",
    "kmeans.fit(train_set_fl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da85a0de-7519-4a32-970a-ae9e02b54fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5], dtype=int32), array([132, 138,  97,  72,  60,   2]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_clusters = kmeans.predict(train_set_fl)\n",
    "np.unique(train_set_clusters, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb0fb6c0-f38d-4193-9d76-2bd48781cfb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5], dtype=int32), array([ 2, 43,  3, 40, 75,  1]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_set_clusters = kmeans.predict(val_set_fl)\n",
    "np.unique(val_set_clusters, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b5f483-9ddc-4c64-8742-fe6e5498c637",
   "metadata": {},
   "source": [
    "## Plot landmarks and corresponding clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bbc0e2-dd17-46b6-99ac-8792a8ea78c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val dataloader\n",
    "val_dataloader = create_dataloader(\n",
    "    task_id=task_id,\n",
    "    batch_size=1,\n",
    "    split='val',\n",
    "    shuffle=False,\n",
    "    params=params,\n",
    "    sampler_n_samples=None,\n",
    ")\n",
    "\n",
    "for i, batch in enumerate(val_dataloader):\n",
    "    images, targets = batch['image'], batch['v_landmarks']\n",
    "    images = images.to(device)\n",
    "    with torch.no_grad():\n",
    "        lmks = model(images, task_id=task_id)\n",
    "    # turn heatmaps to coordinates\n",
    "    image = images.detach().cpu().numpy()[0,0,...]\n",
    "    lmks = max_indices_4d_tensor(lmks)\n",
    "    lmks = lmks.squeeze()\n",
    "    lmks = lmks.cpu().numpy()\n",
    "    lmks_flipped = np.flip(lmks.copy(),1)\n",
    "    lmks_flipped[:,1] = -1 * lmks_flipped[:,1]\n",
    "    clss = val_set_clusters[i]\n",
    "    if i % 10 == 0:\n",
    "        print(clss+1)\n",
    "        plot_landmarks(lmks_flipped)\n",
    "        plot_image_and_vertebral_landmarks(\n",
    "            img_name=\"\",\n",
    "            model_id=\"\",\n",
    "            landmarks=lmks,\n",
    "            image=image,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d21393-5d42-4517-9199-269eedc6c186",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(pd.DataFrame(val_set_clusters),)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
